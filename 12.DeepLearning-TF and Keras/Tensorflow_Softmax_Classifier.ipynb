{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UhNRn7pEro8w"
   },
   "source": [
    "# Softmax Classifier using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QAuadyaFro80",
    "outputId": "000be423-b601-41cf-ad25-9b9da9775d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# credits: https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nD4hN9Gro9L"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-p1oHQDVro9U"
   },
   "source": [
    "\n",
    "Every MNIST data point has two parts: an image of a handwritten digit and a corresponding label. We'll call the images \"x\" and the labels \"y\". Both the training set and test set contain images and their corresponding labels; for example the training images are mnist.train.images and the training labels are mnist.train.labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MS3H9-Kro9W"
   },
   "source": [
    "\n",
    "mnist.train.images is a tensor (an n-dimensional array) with a shape of [55000, 784]. The first dimension is an index into the list of images and the second dimension is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1, for a particular pixel in a particular image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_v5ltd4uro9Z",
    "outputId": "8d504cb9-29ae-4d4f-8870-5bf8764a3b04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points :  55000 number of pixels in each image : 784\n"
     ]
    }
   ],
   "source": [
    "print(\"number of data points : \", mnist.train.images.shape[0],\"number of pixels in each image :\",mnist.train.images.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgaHugyNro9i"
   },
   "source": [
    "\n",
    "we're going to want our class-labels as \"one-hot vectors\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the t-th digit will be represented as a vector which is 1 in the t-th dimension. For example, 3 would be [0,0,0,1,0,0,0,0,0,0]. Consequently, mnist.train.labels is a [55000, 10] array of floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwEk7I3iro9k",
    "outputId": "d89300ad-8623-4fab-f090-f762061740ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points :  10000  length of the one hot encoded label vector : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"number of data points : \", mnist.test.labels.shape[0],\" length of the one hot encoded label vector :\",mnist.test.labels.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iquBvcxro9s"
   },
   "source": [
    "\n",
    "If you want to assign probabilities to an object being one of several different things, softmax (Multiclass Logistic regression) is the thing to do, because softmax gives us a list of values between 0 and 1 that add up to 1. Even later on, when we train more sophisticated models, the final step will be a layer of softmax.\n",
    "\n",
    "A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RiPinIxro9u"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sFc2FZcro9y",
    "outputId": "1e97b7a6-41cb-4a20-b750-acf5d93a6a90",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17772744279889263448\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5929863031256098806\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get a list of devices like GPUs and CPUs available to TF\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Me4O2pkUro93"
   },
   "source": [
    "\n",
    "Sample Output (with a GPU) <br>\n",
    "\n",
    "[name: \"/cpu:0\" device_type: \"CPU\" memory_limit: 268435456 locality { } incarnation: 4402277519343584096,\n",
    "\n",
    "name: \"/gpu:0\" device_type: \"GPU\" memory_limit: 6772842168 locality { bus_id: 1 } incarnation: 7471795903849088328 physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:05:00.0\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQeukILEro94"
   },
   "source": [
    "### Placeholders and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSl4cllIro95"
   },
   "outputs": [],
   "source": [
    "# x isn't a specific value. It's a placeholder. A placeholder can be imagained as \n",
    "# a memory unit that we use to load various mini-batches of input data while training.\n",
    "\n",
    "\n",
    "# We want to be able to input any number of MNIST images, \n",
    "# each flattened into a 784-dimensional vector. \n",
    "\n",
    "# We represent this as a 2-D tensor of floating-point numbers, \n",
    "# with a shape [None, 784]. \n",
    "\n",
    "# (Here None means that a dimension can be of any length.)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# We also need the weights and biases for our model. \n",
    "\n",
    "# We could imagine treating these like additional inputs, \n",
    "# but TensorFlow has an even better way to handle it: Variable. \n",
    "\n",
    "# A Variable is a modifiable tensor that lives in TensorFlow's graph\n",
    "# of interacting operations. \n",
    "\n",
    "# It can be used and even modified by the computation. \n",
    "# For machine learning applications, one generally has the model parameters be Variables.\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6IQPfMero98"
   },
   "outputs": [],
   "source": [
    "# First, we multiply x by W with the expression tf.matmul(x, W). \n",
    "# This is flipped from when we multiplied them in our equation, \n",
    "# where we had Wx , as a small trick to deal with x being a 2D tensor \n",
    "# with multiple inputs. \n",
    "\n",
    "# We then add b, and finally apply tf.nn.softmax.\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kabqZYcaro9_"
   },
   "outputs": [],
   "source": [
    "# y_ is true label of the images, and similar to x\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "# Defining the loss function: multi class log-loss/cross-entropy\n",
    "# First, tf.log computes the logarithm of each element of y. \n",
    "\n",
    "# Next, we multiply each element of y_ with the corresponding element \n",
    "# of tf.log(y). \n",
    "\n",
    "# Then tf.reduce_sum adds the elements in the second dimension of y, \n",
    "# due to the reduction_indices=[1] parameter. \n",
    "\n",
    "#Tutorial for tf.reduce_sum: https://www.dotnetperls.com/reduce-sum-tensorflow\n",
    "\n",
    "# Reduction is an operation that removes one or more dimensions from a tensor by performing \n",
    "# certain operations across those dimensions.\n",
    "\n",
    "# Finally, tf.reduce_mean computes the mean over all the examples in the batch.\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vREdzNYPro-D"
   },
   "outputs": [],
   "source": [
    "# In this case, we ask TensorFlow to minimize cross_entropy \n",
    "# using the gradient descent algorithm with a learning rate of 0.05.\n",
    "\n",
    "# https://www.tensorflow.org/versions/r1.2/api_guides/python/train#Optimizers\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "\n",
    "# What TensorFlow actually does here, behind the scenes,\n",
    "# is to add new operations to your computation-graph which implement backpropagation and gradient descent.\n",
    "# Then it gives you back a single operation which, when run, does a step of gradient descent training, \n",
    "# slightly tweaking your variables to reduce the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DmJqAN3ro-I"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srinu/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# We can now launch the model in an InteractiveSession\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# We first have to create an operation to initialize the \n",
    "# variables we created:\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9dHQaw-ro-M"
   },
   "outputs": [],
   "source": [
    "# Each step of the loop, we get a \"mini-batch\" of one hundred random data \n",
    "# points from our training set. \n",
    "\n",
    "# We run train_step feeding in the batches data to replace \n",
    "# the placeholders\n",
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "# Using small batches of random data is called stochastic training -- in this case, stochastic gradient descent. \n",
    "# Ideally, we'd like to use all our data for every step of training because that would give us a better sense of\n",
    "# what we should be doing, but that's expensive. So, instead, we use a different subset every time. \n",
    "# Doing this is cheap and has much of the same benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02cd-K4uro-Q",
    "outputId": "02c04ee0-8378-4210-ac4d-d1721a2f5dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/41863099\n",
    "# tf.argmax(input, axis=None, name=None, dimension=None)\n",
    "# Returns the index with the largest value across axis of a tensor.\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ian22lpAro-V"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "def plt_dynamic(x, y, y_1, ax, colors=['b']):\n",
    "    ax.plot(x, y, 'b', label=\"Train Loss\")\n",
    "    ax.plot(x, y_1, 'r', label=\"Test Loss\")\n",
    "    if len(x)==1:\n",
    "        plt.legend()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ECWKXHiro-b",
    "outputId": "97010663-7653-4afc-bf80-961d544f0ae2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9087\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# summarizing everything in single cell\n",
    "training_epochs = 100\n",
    "batch_size = 1000\n",
    "display_step = 1\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Soft Max Cross Entropy loss')\n",
    "xs, ytrs, ytes = [], [], []\n",
    "for epoch in range(training_epochs):\n",
    "        train_avg_cost = 0.\n",
    "        test_avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "            train_avg_cost += c / total_batch\n",
    "            c = sess.run(cross_entropy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "            test_avg_cost += c / total_batch\n",
    "\n",
    "        xs.append(epoch)\n",
    "        ytrs.append(train_avg_cost)\n",
    "        ytes.append(test_avg_cost)\n",
    "        plt_dynamic(xs, ytrs, ytes, ax)\n",
    "        \n",
    "\n",
    "plt_dynamic(xs, ytrs, ytes, ax)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tensorflow_Softmax_Classifier.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
